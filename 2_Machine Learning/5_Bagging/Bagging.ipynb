{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5cad0039-31bf-4576-89ba-7d2e9b39d55f",
   "metadata": {},
   "source": [
    "üîπ Bagging (Bootstrap Aggregating)\n",
    "üëâ What it is\n",
    "\n",
    "Bagging trains multiple independent models in parallel on different random subsets of the training data and then aggregates their predictions (usually by voting or averaging).\n",
    "\n",
    "üëâ How it works\n",
    "\n",
    "Create multiple datasets by sampling with replacement (bootstrapping).\n",
    "\n",
    "Train a separate model on each dataset.\n",
    "\n",
    "Combine predictions:\n",
    "\n",
    "Classification ‚Üí Majority voting\n",
    "\n",
    "Regression ‚Üí Average\n",
    "\n",
    "üëâ Key purpose\n",
    "\n",
    "‚úîÔ∏è Reduces variance\n",
    "‚úîÔ∏è Prevents overfitting, especially for high-variance models\n",
    "\n",
    "üëâ Best suited for\n",
    "\n",
    "Models that overfit easily (e.g., decision trees)\n",
    "\n",
    "Large datasets\n",
    "\n",
    "üëâ Popular example\n",
    "\n",
    "Random Forest (classic bagging-based algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4608ab-6242-4e25-bb2c-92639895688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy on Iris Dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1: Import required libraries\n",
    "# ============================================\n",
    "\n",
    "# Load the Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Base model (Decision Tree)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Bagging algorithm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# To measure performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: Load the Iris dataset\n",
    "# ============================================\n",
    "\n",
    "# Iris dataset contains:\n",
    "# - 150 flowers\n",
    "# - 4 features (sepal length, sepal width, petal length, petal width)\n",
    "# - 3 classes (Setosa, Versicolor, Virginica)\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# X = features (measurements of flowers)\n",
    "X = iris.data\n",
    "\n",
    "# y = target labels (flower type as numbers 0,1,2)\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: Split the data\n",
    "# ============================================\n",
    "\n",
    "# We split data so the model learns from one part\n",
    "# and is tested on unseen data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,     # 30% data for testing\n",
    "    random_state=42    # Fix randomness so results don't change\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: Define the base model\n",
    "# ============================================\n",
    "\n",
    "# This is the model Bagging will COPY many times\n",
    "# Decision Trees are chosen because:\n",
    "# - They learn fast\n",
    "# - They overfit easily\n",
    "# - Bagging fixes overfitting (high variance)\n",
    "\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: Create the Bagging model\n",
    "# ============================================\n",
    "\n",
    "bagging_model = BaggingClassifier(\n",
    "\n",
    "    # estimator:\n",
    "    # This tells Bagging WHICH model to repeat\n",
    "    # Here: Decision Tree\n",
    "    estimator=base_model,\n",
    "\n",
    "    # n_estimators:\n",
    "    # How many models (trees) to create\n",
    "    # Think: 50 independent decision-makers\n",
    "    n_estimators=50,\n",
    "\n",
    "    # bootstrap:\n",
    "    # True means \"sampling with replacement\"\n",
    "    # Each tree gets a slightly different version of training data\n",
    "    # Some rows repeat, some are missing\n",
    "    bootstrap=True,\n",
    "\n",
    "    # random_state:\n",
    "    # Fixes randomness so results are reproducible\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 6: Train the Bagging model\n",
    "# ============================================\n",
    "\n",
    "# What happens internally when we call fit():\n",
    "# 1. 50 bootstrapped datasets are created\n",
    "# 2. 50 decision trees are trained independently\n",
    "# 3. All trees are stored inside bagging_model\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 7: Make predictions\n",
    "# ============================================\n",
    "\n",
    "# Each of the 50 trees predicts a class\n",
    "# Final prediction is decided by MAJORITY VOTING\n",
    "\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STEP 8: Evaluate performance\n",
    "# ============================================\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(\"Bagging Accuracy on Iris Dataset:\", accuracy)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# IMPORTANT MEMORY RULE (READ THIS)\n",
    "# ============================================\n",
    "\n",
    "# Bagging =\n",
    "# Same model (Decision Tree)\n",
    "# + Different random data (bootstrapping)\n",
    "# + Parallel training\n",
    "# + Majority voting\n",
    "#\n",
    "# Purpose: Reduce overfitting (variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee9e78a-daad-4347-a0fd-ae66ed212005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Tree Accuracy:on Iris Dataset 1.0\n"
     ]
    }
   ],
   "source": [
    "single_model = DecisionTreeClassifier(random_state=42)\n",
    "single_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_single = single_model.predict(X_test)\n",
    "print(\"Single Tree Accuracy:on Iris Dataset\", accuracy_score(y_test, y_pred_single))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8cb72-2995-46bf-880a-990e85264ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
