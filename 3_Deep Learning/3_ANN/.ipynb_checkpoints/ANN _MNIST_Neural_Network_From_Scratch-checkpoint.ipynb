{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300d957c",
   "metadata": {},
   "source": [
    "# üß† Handwritten Digit Classification using Neural Networks (MNIST)\n",
    "\n",
    "This notebook explains **everything from scratch**:\n",
    "- Reading the dataset\n",
    "- Understanding images as numbers\n",
    "- Preprocessing\n",
    "- Building a Neural Network\n",
    "- Training and prediction\n",
    "\n",
    "This is written to be **beginner-friendly and interview-ready**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5bf9",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "- NumPy ‚Üí numerical operations\n",
    "- Matplotlib ‚Üí image visualization\n",
    "- TensorFlow / Keras ‚Üí Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0680fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:01:54.731868: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-08 20:01:54.789321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-08 20:01:56.029130: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/siva/anaconda3/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2eecb",
   "metadata": {},
   "source": [
    "## Step 2: Load the MNIST Dataset\n",
    "\n",
    "MNIST contains handwritten digits (0‚Äì9).\n",
    "- Each image is **28 √ó 28 pixels**\n",
    "- Pixel values range from **0 to 255**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c920c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63bc23",
   "metadata": {},
   "source": [
    "## Step 3: Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad38462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 60000\n",
      "Training labels: 60000\n",
      "Test images: 10000\n",
      "Test labels: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Training images:', len(x_train))\n",
    "print('Training labels:', len(y_train))\n",
    "print('Test images:', len(x_test))\n",
    "print('Test labels:', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db47b53",
   "metadata": {},
   "source": [
    "## Step 4: Inspect One Image\n",
    "\n",
    "Images are stored as **NumPy arrays**, not image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2792791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73b8b8",
   "metadata": {},
   "source": [
    "## Step 5: Visualize the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e1905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022f195",
   "metadata": {},
   "source": [
    "## Step 6: Normalize Pixel Values\n",
    "\n",
    "Neural Networks perform better when inputs are between **0 and 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train / 255\n",
    "X_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a4ccd",
   "metadata": {},
   "source": [
    "## Step 7: Flatten Images\n",
    "\n",
    "Dense layers require **1D input**.\n",
    "28 √ó 28 ‚Üí 784 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aef68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 784)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 784)\n",
    "\n",
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c3ced",
   "metadata": {},
   "source": [
    "## Step 8: Build the Neural Network\n",
    "\n",
    "- Input layer ‚Üí 784 neurons\n",
    "- Output layer ‚Üí 10 neurons (digits 0‚Äì9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb79b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:02:09.591505: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131485b6",
   "metadata": {},
   "source": [
    "## Step 9: Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0524ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffcb57",
   "metadata": {},
   "source": [
    "## Step 10: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42724c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:02:12.678870: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 727us/step - accuracy: 0.8765 - loss: 0.4671\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.9150 - loss: 0.3043\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.9205 - loss: 0.2834\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.9234 - loss: 0.2736\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.9259 - loss: 0.2671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a91f3e10c20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1625e2",
   "metadata": {},
   "source": [
    "## Step 11: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf2ccaf-b08f-4229-b883-ecd99d509f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:04:08.275810: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.7584536e-06, 8.0930172e-11, 9.0625281e-06, 4.5207841e-03,\n",
       "       7.9872052e-07, 3.2092212e-05, 2.2570376e-10, 9.9496579e-01,\n",
       "       1.9803159e-05, 4.4389773e-04], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "predicted_digit = y_predicted[0]\n",
    "predicted_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9461fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:02:20.180360: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 7\n",
      "Actual digit: 7\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "predicted_digit = np.argmax(y_predicted[0])\n",
    "\n",
    "print('Predicted digit:', predicted_digit)\n",
    "print('Actual digit:', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df0889",
   "metadata": {},
   "source": [
    "## Step 12: Visual Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca614e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec6693",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "You have successfully:\n",
    "- Loaded image data\n",
    "- Converted images to numbers\n",
    "- Normalized and flattened data\n",
    "- Built and trained a Neural Network\n",
    "- Made predictions\n",
    "\n",
    "This is a **complete MNIST baseline model**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
