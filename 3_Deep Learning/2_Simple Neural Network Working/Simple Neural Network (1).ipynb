{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f43ef1-7cfe-43d7-a3e6-7008a955366b",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b090d67-df74-4c06-abe0-473df8ac7224",
   "metadata": {},
   "source": [
    "Neural Network\n",
    "\n",
    "1.Advance Version of Logistic Regression\n",
    "2.number of neurons depends on the number of features - Input Layers - Depends\n",
    "3.number of categories - Output Layers\n",
    "\n",
    "theta0,theta1 - Parameters In machine Learning\n",
    "Weights ,Bias -  Parameters in Deep Learning\n",
    "Forward Propagation\n",
    "Backward Propagation\n",
    "\n",
    "Simple 1 i/p Layer & 1 o/p Layer\n",
    "Shallow 1 hidden layer\n",
    "Dense Neural Network\n",
    "Deep Many hidden layer\n",
    "\n",
    "initial Weight - 0 , bias - 0\n",
    "---------------------------------------------------------\n",
    "Forward Propagation + Backward Propagation = Epoch\n",
    "Backward Propagation  - After Changing the Weight & Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce35a0f-e411-4a6c-a4dd-8db6fc336635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 epoch:\n",
      "0.6931471805599453\n",
      "cost after 100 epoch:\n",
      "0.5020586179991661\n",
      "cost after 200 epoch:\n",
      "0.4448439151612328\n",
      "cost after 300 epoch:\n",
      "0.3979115275585397\n",
      "cost after 400 epoch:\n",
      "0.3590456846967789\n",
      "cost after 500 epoch:\n",
      "0.32654805177827606\n",
      "cost after 600 epoch:\n",
      "0.2990946818904699\n",
      "cost after 700 epoch:\n",
      "0.27566689061159727\n",
      "cost after 800 epoch:\n",
      "0.25548229634006936\n",
      "cost after 900 epoch:\n",
      "0.2379373586492477\n",
      "cost after 1000 epoch:\n",
      "0.2225628943911951\n",
      "cost after 1100 epoch:\n",
      "0.20899075448733584\n",
      "cost after 1200 epoch:\n",
      "0.1969291871801246\n",
      "cost after 1300 epoch:\n",
      "0.18614467111915223\n",
      "cost after 1400 epoch:\n",
      "0.17644847640779723\n",
      "cost after 1500 epoch:\n",
      "0.1676866592266118\n",
      "cost after 1600 epoch:\n",
      "0.15973255199801517\n",
      "cost after 1700 epoch:\n",
      "0.15248107596905414\n",
      "cost after 1800 epoch:\n",
      "0.14584439396391574\n",
      "cost after 1900 epoch:\n",
      "0.13974855674512077\n",
      "The final Weight and Loss\n",
      "[[-5.41785857]\n",
      " [ 6.45588012]] 2.3882958084750783\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "X_data = np.array([[0.4,0.3],[0.6,0.8],[0.7,0.5],[0.9,0.2]])\n",
    "Y_data = np.array([[1],[1],[1],[0]])\n",
    "\n",
    "\"\"\"\n",
    "0.4  0.3   1\n",
    "0.6  0.8   1\n",
    "0.7  0.5   1\n",
    "0.9  0.2   0\n",
    "\"\"\"\n",
    "\n",
    "X = X_data.T\n",
    "Y = Y_data.T\n",
    "\n",
    "W = np.zeros((X.shape[0], 1))\n",
    "b = 0\n",
    "\n",
    "num_samples = float(X.shape[1])\n",
    "for i in range(2000):\n",
    "    Z = np.dot(W.T,X) + b\n",
    "    pred_y = 1/(1 + np.exp(-Z)) #Sigmoid Activation  Function\n",
    "    if(i%100 == 0):\n",
    "      print(\"cost after %d epoch:\"%i)# printing the Cost Fuunction\n",
    "      print (-1/num_samples *np.sum(Y*np.log(pred_y) + (1-Y)*(np.log(1-pred_y)))) # Applying the cost function to the logistic regression\n",
    "        #---------------------Back Ward Propogation --------------------\n",
    "    dW = (np.dot(X,(pred_y-Y).T))/num_samples\n",
    "    db = np.sum(pred_y-Y)/num_samples\n",
    "    W = W - (0.1 * dW) # 0.1 hyperparamer\n",
    "    b = b - (0.1 * db)\n",
    "\n",
    "print(\"The final Weight and Loss\")\n",
    "print (W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6337a954-6dd1-45a5-86e1-b2e4c3654770",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a09beb-3336-4ed7-8ea2-204cdc8a15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a55a69-6dfa-4c5d-9f35-f9eff0b61d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array([[0.4,0.3],[0.6,0.8],[0.7,0.5],[0.9,0.2]])\n",
    "Y_data = np.array([[1],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d204eba-76e1-49bd-a3d8-792c59b6e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 0.3],\n",
       "       [0.6, 0.8],\n",
       "       [0.7, 0.5],\n",
       "       [0.9, 0.2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db426171-6fe5-4609-8e78-5683aff98f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "633eaa8d-44cf-466d-9e2b-b012b2c59d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.array([[1],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d51fd7a5-0382-41d2-a3e7-76cda4215f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75a109b-fa29-43e4-8a12-eb27e715500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data.T\n",
    "Y = Y_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dec8b64-559c-4a2f-8fa6-705d111f680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 0.6, 0.7, 0.9],\n",
       "       [0.3, 0.8, 0.5, 0.2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f13317-8ac1-4308-9ccd-00ee9d0fb681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcc3e1a-7ba8-41e7-a60c-b7f2999dcc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01115570-9fc8-45d3-b22d-629468de0ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e9f0ba1-e6d2-45ab-b395-cd79d6490edf",
   "metadata": {},
   "source": [
    "#Matrix Multiplication Condition\n",
    "\n",
    "\n",
    "Condition for Matrix Multiplication The number of columns in the first matrix must be equal to the number of rows in the second matrix. If ùê¥ A is an ùëö √ó ùëõ m√ón matrix and ùêµ B is a ùëõ √ó ùëù n√óp matrix, then the product ùê¥ ùêµ AB is defined and will be an ùëö √ó ùëù m√óp matrix.\n",
    "\n",
    "rows1*columns1\n",
    "rows2*columns2\n",
    "columns1==rows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31bdcc3a-78df-404a-ab06-59641fbd2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row1 *columns1\n",
    "#row2 *columns2\n",
    "\n",
    "#columns1 === rows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa381ce0-513e-437e-81c4-9cf5713d2b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "473a0315-277f-45ba-9786-31ca04fc8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.6, 0.7, 0.9])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b22c5441-6d2f-4726-82d7-fb4cb36136bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e2e94d-3bb8-4ebd-b890-4f3cd3af5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W = np.zeros((X.shape[0], 1)) # W = np.zeros((2, 1))\n",
    "b = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e2051c-bcbe-4e99-898d-c4581dd591b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.zeros((2,1))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33d6ac5d-0285-4fa3-98a4-3ca58d620f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61cd926c-9f3f-47d5-8bf1-5f82ea7f3a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ad4be9c-8fea-4d36-9d59-7be87d028490",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = float(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b90db3f7-7019-4964-a751-d39a769b1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e398860-5f0c-491d-a6cf-fab730003da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ab652e0-0557-49c2-9c80-587575ff716e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f5fe728-cd55-4209-8d90-59c166b7790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2263071-d035-4134-bc80-0f0f7e133127",
   "metadata": {},
   "source": [
    "# Questions To be Clarified"
   ]
  },
  {
   "cell_type": "raw",
   "id": "874d5e09-04c7-4299-b107-c12f6b5db066",
   "metadata": {},
   "source": [
    "### Questions for Simple Neural Network Code\n",
    "\n",
    "1. **What does the `np.zeros` function do in the context of initializing `W`?**\n",
    "2. **Why do we use the `T` attribute (transpose) for `X` and `Y`?**\n",
    "3. **What is the purpose of the `sigmoid` activation function in the code?**\n",
    "4. **How is the cost function calculated in this neural network?**\n",
    "5. **What does the `shape` attribute of a NumPy array represent?**\n",
    "6. **What does the `import numpy as np` statement do?**\n",
    "7. **What is the shape of `X_data` and `Y_data` after they are defined?**\n",
    "8. **Why do we initialize `b` to 0?**\n",
    "9. **What is the purpose of the `num_samples` variable?**\n",
    "10. **Why do we print the cost every 100 epochs in the training loop?**\n",
    "\n",
    "\n",
    "1. **Why do we perform the transpose operation on `X_data` and `Y_data` before the training loop?**\n",
    "2. **What is the role of the `dW` and `db` variables in the backpropagation step?**\n",
    "3. **Explain why the learning rate (`0.1` in this case) is important for the training process.**\n",
    "4. **How does the code update the weights `W` and bias `b` during each iteration?**\n",
    "5. **Why is it necessary to compute the derivative of the cost function with respect to `W` and `b`?**\n",
    "6. **How does the `np.dot` function work in the context of calculating `Z`?**\n",
    "7. **Why do we use the `np.sum` function when calculating the cost and the derivatives `dW` and `db`?**\n",
    "8. **What would happen if we didn't use an activation function like sigmoid in this neural network?**\n",
    "9. **How would you explain the difference between the forward propagation and backpropagation steps?**\n",
    "10. **What are the benefits and drawbacks of using a small learning rate versus a large learning rate?**\n",
    "\n",
    "\n",
    "1. **How would you modify the code to add a hidden layer to this neural network?**\n",
    "2. **What changes would you make to implement a different activation function, like ReLU, instead of the sigmoid function?**\n",
    "3. **Discuss how you would adjust the code to handle a multi-class classification problem instead of a binary classification problem.**\n",
    "4. **Explain the implications of using a different cost function, such as Mean Squared Error (MSE), in this logistic regression model.**\n",
    "5. **How would you incorporate regularization techniques (like L2 regularization) into this neural network to prevent overfitting?**\n",
    "6. **If you were to normalize `X_data`, how would that affect the training process and the final model?**\n",
    "7. **Explain how you would implement a mini-batch gradient descent instead of using all the samples for each iteration.**\n",
    "8. **How would you modify the code to use a different optimization algorithm, such as Adam or RMSprop?**\n",
    "9. **Describe how the gradient descent algorithm is used to minimize the cost function in this code.**\n",
    "10. **How could you evaluate the performance of this neural network on a separate test set? What metrics would you use?**\n",
    "\n",
    "#### Advanced Questions\n",
    "1. **Discuss the potential impacts of different initializations for weights `W` (e.g., random initialization) on the training process.**\n",
    "2. **How would you handle the issue of vanishing gradients when using the sigmoid activation function in deeper networks?**\n",
    "3. **Explain the trade-offs between bias and variance in the context of this neural network.**\n",
    "4. **How would you adapt this neural network to work with non-linearly separable data?**\n",
    "5. **What strategies can you use to diagnose and fix issues if the neural network is not converging during training?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c235b-fb3c-4efd-852f-34c4e80b858d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
